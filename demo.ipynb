{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "from blocking_utils.blocking_utils import compute_similarity\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "from nltk.util import ngrams\n",
    "import multiprocessing as mp\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.5)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/carloshurtado/Documents/epfl/lauzhack/.venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "global df\n",
    "start_total = time.time()\n",
    "df = pd.read_csv(\"data/processed/external_parties_train.csv\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "block diagram with overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locality Sensitive Hashing\n",
    "\n",
    "hash functions\n",
    "\n",
    "parameters\n",
    "\n",
    "elements in the same name bucket all have a very high similarity score\n",
    "    F1 score at .76 regardless of threshold\n",
    "elements in the same street name bucket have wide ranging similarity scores\n",
    "    F1 score at .55 with threshold 0.1, .83 with threshold .6, .81 with .7\n",
    "\n",
    "run-time: O(buckets * size_of_bucket^2)\n",
    "\n",
    "max block size\n",
    "- higher threshold\n",
    "- prune blocks too big\n",
    "\n",
    "Trade-off\n",
    "few and small buckets: FAST!, higher precision lower recall\n",
    "more buckets, bigger buckets: slooow, lower precision higher recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Similarity\n",
    "\n",
    "threshold, no LLMs, strictness trade-off -> more precision less recall "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "We evaluated our models on the training data. We do so by by looking at each pair of elements and label our prediction as a: \n",
    "* **True Positive**: $i$ and $j$ are the same entity and we predicted so.\n",
    "* **False Positive**: we predicted $i$ and $j$ as the same entity, which is false.\n",
    "* **False Negative**: we did not identify $i$ and $j$ as the same entity.\n",
    "\n",
    "The evaluation metrics we used to guide our modeling are **Precision** and **Recall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
